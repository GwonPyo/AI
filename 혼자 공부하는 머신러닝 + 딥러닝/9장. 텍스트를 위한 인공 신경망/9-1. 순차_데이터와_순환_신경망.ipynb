{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "9-1. 순차 데이터와 순환 신경망.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nul6Ry4z9KoH"
      },
      "source": [
        "**'순차 데이터(sequential data)'**는 **텍스트와 '시계열 데이터(time series data)**'와 같이 순서에 의미가 있는 데이터를 말한다. 예를 들어 \"I am a boy\"는 쉽게 이해할 수 있지만 \"boy am a I\"는 말이 되지 않는다. 또 일별 온도를 기록한 데이터에서 날짜 순서를 뒤죽박죽 섞는다면 내일의 온도를 쉽게 예상할 수 없다.\n",
        "\n",
        "지금까지 우리가 보았던 데이터는 순서와 상관이 없었다. 생선 데이터, 패션 MNIST 데이터는 어떤 샘플이 먼저 주입되어도 모델의 학습에 큰 영향을 미치지 않았다. 실제로 신경망 모델에 데이터를 전달할 때 샘플을 랜덤하게 섞은 후 훈련 세트와 검증 세트로 나누었으며 골고루 섞는 편이 결과가 더 좋았다.\n",
        "\n",
        "하지만 텍스트 데이터는 단어의 순서가 중요한 순차 데이터이다. 이런 데이터는 **순서를 유지하며 신경망에 주입**해야한다. 즉, 단어의 순서를 섞어서 주입하면 안된다. 따라서 **순차 데이터를 다룰 때는 이전에 입력한 데이터를 기억하는 기능이 필요**하다. 예를 들어 \"별로지만 추천해요\"에서 \"추천해요\"가 입력될 때 \"별로지만\"을 기억하고 있어야 이 댓글이 무조건 긍정적이라고 판단하지 않을 것이다.\n",
        "\n",
        "완전 연결 신경망이나 합성곱 신경망은 이런 기억 장치가 없다. 하나의 샘플을 사용해 정방향 계산을 수행하면 그 샘플은 버려지고 다음 샘플을 처리할 때 재사용하지 않는다. 이렇게 입력 데이터의 흐름이 앞으로만 전달되는 신경망을 **'피드포워드 신경망(feedforward neural network, FFNN)'**이라고 한다.\n",
        "\n",
        "* 완전 연결 신경망, 합성곱 신경망은 모두 피드포워드 신경망에 속한다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZvnFgFc_YZG"
      },
      "source": [
        "신경망이 이전에 처리했던 샘플을 다음 샘플을 처리하는데 재사용하기 위해서는 이렇게 데이터의 흐름이 앞으로만 전달되어서는 곤란하다. 다음 샘플을 위해서 이전 데이터가 신경망 층에 순환될 필요가 있다. 이런 신경망이 **'순환 신경망(recurrent neural network, RNN)'**이다.\n",
        "\n",
        "순환 신경망은 완전 연결 신경망에 **이전 데이터의 처리 흐름을 순환하는 고리 하나만 추가**하면 된다. 즉, **뉴런의 출력이 다시 자기 자신으로 전달되는 모습**을 보인다. 이런 구조를 통해 어떤 샘플을 처리할 때 이전에 사용했던 데이터를 재사용할 수 있다. a, b, c 3개의 샘플을 처리하는 순환 신경망의 뉴런이 있다고 가정해 보자. 아래는 순환 신경망의 처리 과정이다.\n",
        "\n",
        "* a 처리 과정: a를 처리하고 난 출력 return_a가 다시 뉴런으로 들어간다.\n",
        "* b 처리 과정: b를 처리할 때 return_a를 함께 사용한다.\n",
        "* c 처리 과정: c를 처리할 때 return_b를 함께 사용한다.\n",
        "\n",
        "위와 같이 샘플을 처리하는 한 단계를 **'타입스텝(timestep)'**이라고 말한다.\n",
        "\n",
        "이를 통해 b의 출력(return_b)에는 a에 대한 정보가 어느 정도 포함되고 c의 출력(return_c)에는 b와 a에 대한 정보가 포함된다. 물론 return_c에는 a에 대한 정보보다 b에 대한 정보가 더 많다. 순환 신경망은 이전 타임스텝의 샘플을 기억하지만 **타임스텝이 오래될수록 순환되는 정보는 희미해진다**.\n",
        "\n",
        "순환 신경망에서는 층을 **'셀(cell)'**이라고 부르며 셀의 출력은 **'은닉 상태(hidden state)'**라고 부른다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qS3SuQOGD8CG"
      },
      "source": [
        "순환 신경망 역시 입력에 어떤 가중치를 곱하고 활성화 함수를 통과시켜 다음 층으로 보낸다. 일반적으로 은닉층의 활성화 함수로는 **'하이퍼볼릭 탄젠트(hyperbolic tangent)' 함수**인 tanh가 많이 사용된다. tanh 함수는 시그모이드 함수와 비슷하지만 시그모이드 함수는 0 ~ 1 사이의 범위를 가지지만 tanh 함수는 **-1 ~ 1사이의 값**을 가진다.\n",
        "\n",
        "이전에 피드포워드 신경망에서 뉴런은 입력과 가중치를 곱했다. 순환 신경망도 동일하지만 타임스텝의 은닉 상태에 곱해지는 가중치가 추가된다. **셀은 입력과 이전 타임스텝의 은닉 상태를 사용하여 현재 타임스텝의 은닉상태를 만든다.** 피드포워드 신경망과 마찬가지로 뉴런마다 하나의 절편을 가진다.\n",
        "\n",
        "맨 처음 타임스텝에서 사용되는 이전 은닉 상태는 0으로 초기화하고 계산을 시작한다. 이후 타임스텝마다 이전 타임스텝의 은닉 상태와 가중치(w)를 곱해준다. 이때 가중치는 타임스텝에 따라 변화되는 뉴런을 학습한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1EOiypxH9-F"
      },
      "source": [
        "순환 신경망 셀의 가중치 크기를 계산해보자. 순환층에 입력되는 특성의 개수가 4개, 셀의 뉴런이 3개라고 가정하자.\n",
        "\n",
        "**입력층과 순환층의 뉴런이 모두 완전 연결된다.** 따라서 입력과 곱해지는 가중치의 개수는 아래와 같다.\n",
        "\n",
        "* 입력과 곱해지는 가중치: 4 × 3 ＝ 12\n",
        "\n",
        "순환층에 있는 첫 번째 뉴런(r₁) 의 **은닉 상태가 다음 타임스텝에 재사용될 때 첫 번째 뉴런과 두 번째 뉴런, 세 번째 뉴런에 전달**된다. 두 번째 뉴런의 은닉 상태와 세 번째 뉴런의 은닉 상태도 마찬가지로 첫 번째 뉴런과 두 번째 뉴런, 세 번째 뉴런에 모두 전달된다. 따라서 가중치의 개수는 아래와 같다.\n",
        "\n",
        "* 은닉 상태와 곱해지는 가중치: 3 × 3 ＝ 9\n",
        "\n",
        "절편의 개수는 뉴런의 개수와 동일하다. 따라서 총 모델 파라미터의 개수는 아래와 같다.\n",
        "* 모델 파라미터: 12 ＋ 9 ＋ 3 = 24"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9NHE3VTLNZF"
      },
      "source": [
        "이번에는 순환층의 입력과 출력에 대해 생각해보자. 이전 장에서 배웠던 합성곱 층의 입력은 전형적으로 하나의 샘플이 3개의 차원(너비, 높이, 채널)을 가진다. **입력이 합성곱-폴링 층을 통과하면 너비, 높이, 채널의 크기가 달라지지만 차원의 개수는 그대로 유지된다.**\n",
        "\n",
        "순환층은 일반적으로 샘플마다 2개의 차원을 가진다. 보통 하나의 샘플을 하나의 **'시퀀스(sequence)'**라고 부른다. 이때 시퀀스의 길이가 타임스텝 길이가 된다.\n",
        "\n",
        "예를 들어, 샘플에 \"I am a boy\"란 문장이 들어 있다고 가정하자. 이 샘플은 4개의 단어로 이루어져 있다. 또 각 단어를 3개의 어떤 숫자로 표현한다고 가정하자.(숫자 표현에 대해서는 다음 절에서 다룬다.) 즉, 셈플의 크기는 (1, 4, 3)이라고 생각할 수 있다. **이런 입력이 순환층을 통과하면 두 번째, 세 번째 차원이 사라지고 순환층의 뉴런 개수만큼 출력된다.**\n",
        "\n",
        "하나의 샘플은 시퀀스 길이(단어 개수)와 단어 표현의 2차원 배열이다. 순환층을 통과하면 1차원 배열로 바뀐다. 이 1차원 배열의 크기는 순환층의 뉴런 개수에 의해 결정된다. 앞에서는 셀이 모든 타임스텝에서 출력을 만드는 것 처럼 표현했지만 사실 **순환층은 기본적으로 마지막 타임스텝의 은닉 상태만 출력으로 내보낸다**. 입력된 시퀀스 길이를 모두 읽어서 정보를 마지막 은닉 상태에 압축하여 전달하는 것처럼 볼 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ENvAt2MNlTV"
      },
      "source": [
        "순환 신경망도 완전 연결 신경망이나 합성곱 신경망처럼 여러 개의 층을 쌓을 수 있다. 순환층을 여러 개 쌓았을 때 셀의 출력은 달라진다. 셀의 입력은 샘플마다 타임스텝과 단어 표현으로 이루어진 2차원 배열이어야 한다. 따라서 **첫 번째 셀이 마지막 타임스텝의 은닉 상태만 출력해서는 안된다**. 이런 경우에는 **마지막 셀을 제외한 다른 모든 셀은 모든 타임스텝의 은닉 상태를 출력한다**. 두 개의 순환 신경망이 연결되어있다고 가정하자.\n",
        "\n",
        "* 첫 번째 셀: 모든 타임스텝의 은닉 상태 출력\n",
        "* 두 번째 셀: 마지막 타임스텝의 은닉 상태만 출력\n",
        "\n",
        "다음 절에서 위와 같은 예를 직접 다루어보자."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qwRrAzeOYQO"
      },
      "source": [
        "마지막으로 출력층의 구성에 대해 알아보자. 합성곱 신경망과 마찬가지로 마지막에는 **밀집층을 두어 클래스를 분류**한다. 다중 분류일 경우에는 출력층에 클래스 개수만큼 뉴런을 두고 소프트맥스 활성화 함수를 사용한다. 이중 분류일 경우 하나의 뉴런을 두고 시그모이드 활성화 함수를 사용한다. 합성곱 신경망과 다른 점은 **마지막 셀의 출력이 1차원이기 때문에 Flatten 클래스로 펼칠 필요가 없다**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIr6m_15O2At"
      },
      "source": [
        "# 정리\n",
        "\n",
        "핵심 포인트\n",
        "* 순차 데이터: **텍스트나 시계열 데이터와 같이 순서에 의미가 있는 데이터**이다. 글, 대화, 일자별 날씨, 일자별 판매 실적 등이 있다.\n",
        "* 순환 신경망: **순차 데이터에 잘 맞는 인공 신경망의 한 종류**이다. 순차 데이터를 처리하기 위해 고안된 순환층을 1개 이상 사용한 신경망을 순환 신경망이라고 부른다.\n",
        "* 셀: **순환 신경망에서는 순환층**을 셀이라고 부른다. 일반적인 인공 신경망과 마찬가지로 하나의 셀은 여러 개의 뉴런으로 구성된다.\n",
        "* 은닉 상태: **순환 신경망에서 셀의 출력**을 은닉 상태라고 부른다. 은닉 상태는 다음 층으로 전달될 뿐만 아니라 셀이 다음 타임스텝의 테이터를 처리할 때 재사용된다."
      ]
    }
  ]
}