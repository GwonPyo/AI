{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8-1. 함성곱 신경망의 구성 요소.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBnOUW3uIt_U"
      },
      "source": [
        "**'합성곱(convolution)'**은 입력 데이터에 도장을 찍어서 유용한 데이터만 드러나게 하는 것으로 비유할 수 있다.\n",
        "\n",
        "**밀집층은 뉴런마다 입력 개수만큼의 가중치가 있었다.** 즉, 모든 입력에 가중치를 곱한다. 입력 데이터가 10개라 가정하자. 인공 신경망은 처음에 가중치 w1~w10과 절편 b를 랜덤하게 초기화한다. 이후 경사 하강법 알고리즘을 사용하여 에포크를 반복하며 손실이 낮아지도록 최적의 가중치와 절편을 찾아간다.\n",
        "\n",
        "합성곱은 밀집층의 계산과 조금 다르다. **입력 데이터 전체에 가중치를 적용하는 것이 아니라 일부에 가중치를 곱한다.** 예를 들어보자. 뉴런이 3개의 가중치를 가진다고 가정하자. 이때 입력이 10개라면 아래와 같이 여러개의 출력을 만들게 된다.\n",
        "\n",
        "입력: [3, 1, 0, 7, 6, 4, 8, 2, 4, 5] \n",
        "\n",
        "* 3 × w1 ＋ 1 × w2 ＋ 0 × w3 ＋ b\n",
        "* 1 × w1 ＋ 0 × w2 ＋ 7 × w3 ＋ b\n",
        "* ...\n",
        "* 2 × w1 ＋ 4 × w2 ＋ 5 × w3 ＋ b\n",
        "\n",
        "가중치 w1~w3이 입력의 처음 3개 특성과 곱해져 1개의 출력을 만든다. 그 다음 뉴런이 한 칸 아래로 이동해 두 번째부터 네 번째 특성과 곱해져 새로운 출력을 만든다. 단, 첫 번째 합성곱에 사용된 가중치와 절편(b)은 두 번째 합성곱과 동일하다. 따라서 총 8개의 출력을 만들어낸다. 이때 합성곱 층의 뉴런에 있는 **가중치 개수는 하이퍼파라미터이다**.\n",
        "\n",
        "**'합성곱 신경망(convolutional neural network, CNN)'**에서는 완전 연결 신경망과 달리 뉴런을 **'필터(filter)'** 혹은 **'커널(kernel)'**이라고 부른다.\n",
        "\n",
        "* **'완전 연결 신경망'**이란 **'완전 연결 층(fully connected layer)'(다른 말로 밀집층)**만 사용하여 만든 신경망이다.\n",
        "* 케라스 API와 이름을 맞춰 뉴런 개수를 이야기할 때는 필터, 입력에 곱해지는 가중치를 의미할 때는 커널이라고 부르자."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Keuq81hhMRvE"
      },
      "source": [
        "합성곱의 장점은 1차원이 아니라 2차원 입력에도 적용할 수 있다는 점이다.\n",
        "\n",
        "**입력이 2차원 배열이면 필터도 2차원이어야 한다.** 입력의 크기를 (4, 4), 필터의 커널 크기를 (3, 3)이라고 가정하자. 이전에 말했지만, 커널 크기는 우리가 지정해야 할 파라미터이다.\n",
        "\n",
        "먼저 입력 데이터의 왼쪽 위 모서리부터 합성곱을 시작한다. 입력의 9개의 원소와 커널의 9개의 가중치를 곱한후 1개의 출력을 만든다. 물론 절편도 더한다. 그 다음 필터가 오른쪽으로 한 칸 이동하여 합성곱을 수행한다. 입력의 너비가 4이므로 더 이상 오른쪽으로 이동할 수 없다. 따라서 한 칸 아래로 이동하여 다시 왼쪽에서부터 합성곱을 시작한다. 입력과 가중치의 행과 열을 맞춰 곱셈하고 모두 더하는 게 전부이다.\n",
        "\n",
        "필터는 총 4번 이동할 수 있었다. 따라서 총 4개의 출력을 만든다. 단 필터가 입력에 놓였던 위치와 맞게 2차원으로 배치된다. 따라서 (2, 2)형태로 결과를 출력한다. 이렇게 합성곱 계산을 통해 얻은 출력을 **'특성 맵(feature map)'**이라고 부른다.\n",
        "\n",
        "밀집층에서 여러 개의 뉴런을 사용하듯이 합성곱 층에서도 여러 개의 필터를 사용한다. 여러 개의 필터를 사용하여 만들어진 특성 맵은 순서대로 쌓인다. 예를 들어, 이전 예시에서 3개의 필터를 사용했다고 가정하면 (2, 2, 3) 크기의 3차원 배열이 된다.\n",
        "\n",
        "**밀집층에 있는 뉴런의 가중치가 모두 다르듯이 합성곱 층의 가중치도 모두 다르다.**\n",
        "\n",
        "실제 계산은 밀집층과 동일하게 **단순히 입력과 가중치를 곱하는 것이지만 2차원 형태를 유지하는 점이 다르다**. 또 입력보다 훨씬 작은 크기의 커널을 사용하고 입력 위를 (왼쪽에서 오른쪽, 위에서 아래로) 이동하면서 **2차원 특성 맵을 만든다**. 이렇게 2차원 구조를 그대로 사용하여 합성곱 신경망이 이미지 처리 분야에서 뛰어난 성능을 발휘한다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gA6SbkOaPqiL"
      },
      "source": [
        "케라스의 층은 모두 **keras.layers 패키지** 아래 클래스로 구현되어있다. 입력 위를 이동하는 합성곱은 **Conv2D 클래스**로 제공한다.\n",
        "\n",
        "* from tensorflow import keras\n",
        "* keras.layers.Conv2D(10, kernel_size = (3, 3), activation = 'relu')\n",
        "\n",
        "첫 번째 매개변수는 **필터의 개수**이다. **kernel_size 매개변수**는 필터에 사용할 커널의 크기를 지정한다. 필터의 개수와 커널의 크기는 반드시 지정해야한다. 마지막으로 **활성화 함수**를 지정한다.\n",
        "\n",
        "* 일반적으로 특성 맵은 활성화 함수를 통과한 값을 나타낸다.\n",
        "* 커널의 크기는 하이퍼파라미터이다. 하지만 일반적으로 (3, 3)이나 (5, 5) 크기가 권장된다.\n",
        "\n",
        "케라스 API를 이용해 합성곱 층을 사용하려면 이전에 Dense 층을 사용했던 자리에 Conv2D 층을 넣으면 된다.\n",
        "\n",
        "합성곱 신경망의 정의는 무엇일까? **일반적으로 1개 이상의 합성곱 층을 쓴 인공 신경망을 합성곱 신경망이라고 부른다.** 즉, 꼭 합성곱 층만 사용한 신경망을 합성곱 신경망이라고 부르는 것은 아니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yK10GuPRUG8"
      },
      "source": [
        "앞에서 (4, 4) 크기의 입력에 (3, 3) 크기의 커널을 적용하여 (2, 2) 크기의 특성 맵을 만들었다. 이때 커널의 크기는 그대로 두고 출력의 크기를 입력의 크기와 동일하게 만드려면 어떻게 해야 할까?\n",
        "\n",
        "(4, 4) 입력과 동일한 크기의 출력을 만드려면 **더 큰 입력에 합성곱을 하는 척하면 된다**. 예를 들어, 실제 입력 크기는 (4, 4)이지만 (6, 6)처럼 다룬다면 (3, 3) 크기의 커널로 합성곱을 했을 때 (4, 4) 크기의 출력을 만들 수 있다.\n",
        "\n",
        "이렇게 입력 배열의 주위를 가상의 원소로 채우는 것을 **'패딩(padding)'**이라고 한다. **실제 입력값이 아니기 때문에 패딩은 0으로 채운다.** 즉, (4, 4) 크기의 입력에 0을 1개 패딩하면 (6, 6) 크기의 입력이 된다. 패딩은 커널이 도장을 찍을 횟수를 늘리는 역할밖에 하지 않는다. 실제 값은 0으로 채워지므로 계산에 영향을 미치지 않는다.\n",
        "\n",
        "이렇게 입력과 특성 맵의 크기를 동일하게 만들기 위해 입력 주위에 0으로 패딩하는 것을 **'세임 패딩(same padding)'**이라고 한다. 합성곱 신경망에서는 세임 패딩을 많이 사용한다.\n",
        "\n",
        "패딩 없이 순수한 입력 배열에서만 합성곱을 하여 특성맵을 만드는 경우를 **'밸리드 패딩(valid padding)'**이라고 한다. 밸리드 패딩은 특성 맵의 크기가 줄어들 수 밖에 없다.\n",
        "\n",
        "그런데 왜 합성곱에 패딩을 많이 사용할까?\n",
        "\n",
        "만약 패딩이 없다면 (4, 4) 크기의 입력에 합성곱을 할 때 네 모서리에 있는 값들은 한 번씩만 계산에 적용된다. 반면 다른 원소들은 2번 이상 커널과 계산된다. 심지어 있는 4개 원소는 4번의 합성곱 계산에 모두 포함된다. 만약 이 입력을 이미지라고 생각하면 **모서리에 있는 중요한 정보가 특성 맵으로 잘 전달되지 않을 수 있다**. 하지만 패딩을 적용하면 모서리 값들은 4번, 나머지 값들은 6번 이상 계산에 포함된다. 중앙에 있는 값들은 9번 계산에 포함된다. **즉, 패딩을 적용하지 않았을 때 보다 비율 차이가 크게 줄어든다(4:1 <-> 9:4).** 만약 2픽셀을 패딩 하면 중앙부와 모서리 픽셀이 합성곱에 참여하는 비율이 동일해진다.\n",
        "\n",
        "정리하자면, 적절한 패딩은 이미지 주변에 있는 정보를 잃어버리지 않도록 도와준다. 따라서 일반적인 합성곱 신경망에서는 세임 패딩이 많이 사용된다. 케라스 Conv2D 클래스에서 **padding 매개변수**로 패딩을 지정할 수 있다. 기본값은 'valid'로 밸리드 패딩을 나타낸다. 세임 패딩을 사용하려면 'same'으로 지정하면 된다.\n",
        "\n",
        "* keras.layers.Conv2D(10, kernel_size = (3, 3), activation = 'relu', padding = 'same')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOKo6b5fXxuG"
      },
      "source": [
        "지금까지 합성곱 연산은 좌우, 위아래 한 칸씩 이동했다. 하지만 두 칸씩 건너뛸 수도 있다. 이런 이동 크기를 **'스트라이드(stride)'**라고 한다. 스트라이드는 기본으로 1이다. 케라스의 Conv2D 클래스의 **strides 매개변수**로 지정할 수 있다.\n",
        "\n",
        "* keras.layers.Conv2D(10, kernel_size = (3, 3), activation = 'relu', padding = 'same', strides = 1)\n",
        "\n",
        "strides 매개변수는 오른쪽으로 이동하는 크기와 아래쪽으로 이동하는 크기를 (1, 1)과 같이 튜플 형태로 지정할 수 있다. 하지만 이런 경우는 드물다. 또한 1보다 큰 스트라이드를 사용하는 경우도 드물다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnEqMbsrYifu"
      },
      "source": [
        "**'폴링(pooling)'**은 합성곱 층에서 만든 특성 맵의 가로세로 크기를 줄이는 역할을 수행한다. 하지만 특성 맵의 개수는 줄이지 않는다. 예를 들어 (2, 2, 3) 크기의 특성 맵에 풀링을 적용하면 (1, 1, 3) 크기의 특성 맵이 된다.\n",
        "\n",
        "풀링도 합성곱처럼 입력 위를 지나가면서 도장을 찍는다. 하지만 풀링에는 가중치가 없고 도장을 찍은 영역에서 가장 큰 값을 고르거나 평균값을 계산한다. 이를 각각 **'최대 폴링(max pooling)'**과 **'평균 폴링(average pooling)'**이라고 부른다.\n",
        "\n",
        "* 풀링 층의 출력도 특성 맵이라고 부른다.\n",
        "\n",
        "이전에 합성곱에서는 커널이 한 칸씩 이동하여 겹치는 부분이 있었다. 하지만 **풀링은 겹치지 않고 이동한다.** 즉, 풀링의 크기가 (2, 2)이면 가로세로 두 칸씩 이동한다. 즉 스트라이드가 2이다.\n",
        "\n",
        "풀링은 가중치가 없고 풀링 크기와 스트라이드가 같기 때문에 이해하기 쉽다. 또 패딩도 없다. 케라스에서는 **MaxPooling2D 클래스**로 최대 풀링을 수행할 수 있다.\n",
        "\n",
        "* keras.layers.MaxPooling2D(2)\n",
        "\n",
        "첫 번째 매개변수로 풀링의 크기를 지정한다. **대부분 폴링의 크기는 2이다.** 즉, 가로 세로를 절반으로 줄인다. 가로 세로 방향의 풀링 크기를 다르게 하려면 (2, 3)처럼 튜플로 지정할 수 있지만 이런 경우는 드물다.\n",
        "\n",
        "합성곱 층과 동일하게 **strides와 padding 매개변수**를 제공한다. strides의 기본값은 자동으로 풀링의 크기이므로 지정할 필요가 없으며 padding의 기본값은 'valid'로 패딩을 하지 않는다. 따라서 이 매개변수들을 바꿀 일은 거의 없다. 이전에 쓴 코드와 아래 코드는 동일한 코드이다.\n",
        "\n",
        "* keras.layers.MaxPooling2D(2, strides = 2, padding = 'valid')\n",
        "\n",
        "평균 풀링은 AveragePooling2D 클래스로 제공한다. **많은 경우 평균 풀링보다 최대 풀링을 많이 사용한다.** 평균 풀링은 특성 맵에 있는 중요한 정보를 희석시킬 수 있기 때문이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiPi49W8cvPm"
      },
      "source": [
        "전체 과정을 정리해보자.\n",
        "\n",
        "우리는 입력으로 (4, 4) 크기의 데이터를 줄 예정이다. 이때 커널의 크기는 (3, 3)이고 **세임 패딩이므로 1픽셀이 입력 데이터 주변에 추가**된다. 그 다음 패딩이 추가된 입력에서 합성곱이 수행된다. \n",
        "\n",
        "합성곱의 필터가 3개라고 했을 때, 이 **필터들은 서로 다른 가중치와 절편을 가진다**. 또한 합성곱의 **스트라이드는 항상 1**이기 때문에 만들어지는 출력은 입력과 동일한 (4, 4)이다. 3개의 필터가 하나씩 합성곱의 출력을 만들기 때문에 (4, 4, 3) 크기의 특성 맵이 만들어진다. 밀집층과 마찬가지로 합성곱 층에서도 활성화 함수를 적용하며 **합성곱 층은 활성화 함수로 렐루 함수를 많이 사용**한다.\n",
        "\n",
        "그 다음 풀링 층을 이용해 특성 맵의 가로세로 크기를 줄인다. 풀링을 사용하는 이유는 합성곱에서 **스트라이드를 크게 하여 특성 맵을 줄이는 것보다 풀링 층에서 크기를 줄이는 것이 경험적으로 더 나은 성능을 제공하기 때문**이다.\n",
        "\n",
        "**합성곱 신경망은 이렇게 합성곱 층에서 특성 맵을 생성하고 폴링에서 크기를 줄이는 구조가 쌍을 이룬다.**\n",
        "\n",
        "폴링을 거친 특성 맵의 크기는 (2, 2, 3)이된다. **밀집층인 출력층에 전달하려면 이 3차원 배열을 1차원 배열로 펼쳐야한다.** 이 배열은 12개의 원소를 가진 1차원 배열이고 출력층의 입력이 된다.\n",
        "\n",
        "출력층에 3개의 뉴런이 있다고 가정하면 3개의 클래스를 분류하는 다중 분류 문제일 것이다. 출력층에서 계산된 값은 소프트맥스 활성화 함수를 거쳐 최종 예측 확률이 된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9JgIr9KehDV"
      },
      "source": [
        "지금까지 우리는 흑백 이미지를 이용하였기 때문에 2차원 배열로 표현이 가능했다. 하지만 컬러 이미지는 RGB 채널로 구성되어 있어 3차원 배열로 표시해야한다.\n",
        "\n",
        "하나의 컬러 이미지는 너비와 높이 차원 외에 깊이 차원이 있다. 예를 들어, 앞의 예제 입력이 (4, 4)가 아니라 (4, 4, 3)이 되는 것이다.\n",
        "\n",
        "이런 이미지에 합성곱을 수행하려면 도장도 깊이가 필요하다. 즉, 커널의 크기가 (3, 3, 3)이 되어야한다. **커널 배열의 깊이는 항상 입력의 깊이와 같아야 한다는 의미이다.**\n",
        "\n",
        "사실 케라스의 합성곱 층은 항상 3차원 입력을 기대한다. 하지만 패션 MNIST 데이터처럼 흑백 이미지인 경우 깊이 차원이 1인 3차원 배열로 변환하여 전달한다.\n",
        "\n",
        "이와 비슷한 경우가 또 있다. 합성곱 층-풀링 층 다음에 다시 합성곱 층이 온다고 가정하자. 첫 번째 합성곱 층의 필터 수가 5개라고 가정하면 특성 맵의 크기는 (4, 4, 5)일 것이다. 두 번째 합성곱 층에서 필터의 너비와 높이가 각각 3이라면 이 필터의 커널 크기는 (3, 3, 5)가 된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXxLtMqIftx2"
      },
      "source": [
        "정리하자면, 합성곱 신경망에서 필터는 이미지에 있는 어떤 특징을 찾는다고 생각할 수 있다. 처음에는 간단한 기본적인 특징(직선, 곡선 등)을 찾고 층이 깊어질수록 다양하고 구체적인 특징을 감지할 수 있도록 필터의 개수를 늘린다. 또 어떤 특징이 이미지의 어느 위치에 놓이더라도 쉽게 감지할 수 있도록 너비와 높이 차원을 점점 줄인다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAZ6kjJgf9yG"
      },
      "source": [
        "# 정리\n",
        "\n",
        "핵심 포인트\n",
        "* 합성곱: **밀집층과 비슷하게 입력과 가중치를 곱하고 절편을 더하는 선형 계산**이다. 하지만 합성곱은 입력 전체가 아니라 일부만 사용하여 선형 계산을 수행한다.\n",
        "* 필터: **합성곱 층의 뉴런에 해당**한다. 필터의 가중치와 절편을 종종 커널이라고도 부른다. 커널의 크기는 (3, 3) 또는 (5, 5)가 자주 사용된다. 커널의 깊이는 입력의 깊이와 같다.\n",
        "* 특성 맵: **합성곱 층이나 풀링 층의 풀력 배열을 의미**한다.\n",
        "* 패딩: **합성곱 층의 입력 주위에 추가한 0으로 채워진 픽셀**이다. 패딩을 사용하지 않는 것을 밸리드 패딩, 입력과 출력의 크기를 동일하게 만들기 위해 패딩을 추가하는 것을 세임 패딩이라고 한다.\n",
        "* 스트라이드: **합성곱 층에서 필터가 입력 위를 이동하는 크기**이다.\n",
        "* 풀링: **가중치가 없고 특성 맵의 가로세로 크기를 줄이는 역할을 수행**한다."
      ]
    }
  ]
}