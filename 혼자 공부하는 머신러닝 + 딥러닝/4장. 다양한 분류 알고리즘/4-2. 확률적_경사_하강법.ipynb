{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "4-2. 확률적 경사 하강법.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "이전에 만들 모델에 샘플을 추가하려고 한다. 생선은 어느 생선이 먼저올지도 모르고 그렇다고 모든 생선이 올 때까지 기다릴 수도 없다. 어떻게 해야할까?\r\n",
        "\r\n",
        "* 기존의 훈련 데이터에 새로운 데이터를 추가해 모델을 매일매일 다시 훈련한다.\r\n",
        "\r\n",
        "이렇게 하면 매일 추가되는 새로운 데이터를 활용해 모델을 훈련할 수 있다. 하지만 시간이 지날수록 데이터가 늘어난다. 시간이 지날 수록 훈련하기위한 서버를 늘려야 할 것이다. 따라서 지속 가능한 방법은 아니다.\r\n",
        "\r\n",
        "* 새로운 데이터를 추가할 때 이전 데이터를 버림으로써 훈련 데이터 크기를 일정하게 유지한다.\r\n",
        "\r\n",
        "이렇게 하면 데이터셋의 크기가 너무 커지지 않을 수 있다. 하지만 데이터를 버릴 때 다른 데이터에 없는 중요한 생선 데이터가 포함되어 있다면 앞으로 모델이 그 생선을 제대로 예측하지 못할 수 있다.\r\n",
        "\r\n",
        "* 훈련한 모델을 버리지 않고 새로운 데이터에 대해서만 조금씩 훈련한다.\r\n",
        "\r\n",
        "이런 훈련 방식을 **'점진적 학습'** 또는 **'온라인 학습'**이라고 부른다. 대표적인 점진적 학습 알고리즘은 **'확률적 경사 하강법(Stochastic Gradient Descent)'**이다.\r\n",
        "사이킷런에서는 확률적 경사 하강법을 위한 클래스를 제공한다. 그럼 이 방식이 어떤 알고리즘이고, 왜 중요한지 알아보자."
      ],
      "metadata": {
        "id": "gLlYbQT4txUC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "확률적 경사 하강법에서 확률적이란 말은 '무작위하게' 혹은 '랜덤하게'의 기술적 표현이다. 경사는 '기울기'를 뜻하며 하강법은 '내려가는 방법'이다. 즉, **경사 하강법은 '내려가는 방법'을 의미**한다.\n",
        "\n",
        "산에서 내려온다고 생각해보자. 집으로 돌아가려면 등산로 입구까지 내려가야 한다. 이때 **가장 빠른 길은 경사가 가장 가파른 길**이다.\n",
        "\n",
        "경사 하강법이 바로 위와 같은 방식이다. 가장 가파른 경사를 따라 원하는 지점에 도달하는 것이 목표이다. 이때 가장 가파른 길을 찾아 내려오지만 **조금씩 내려오는 것이 중요**하다. 이렇게 **내려오는 과정이 바로 경사 하강법 모델을 훈련하는 것**이다.\n",
        "\n",
        "이제 확률적이란 말을 이해해보자. 경사 하강법으로 내려올 때 가장 가파른 길을 찾는 방법은 무엇일까? 훈련 세트를 사용해  모델을 훈련하기 때문에 경사 하강법도 훈련 세트를 사용하여 가장 가파른 길을 찾는다. **이때 전체 샘플을 사용하지 않고 딱 하나의 샘플을 훈련 세트에서 랜덤하게 골라 가장 가파른 길을 찾는다.** 이처럼 훈련 세트에서 **랜덤하게 하나의 샘플을 고르는 것**이 바로 확률적 경사 하강법이다.\n",
        "\n",
        "조금 더 자세히 설명하면, 확률적 경사 하강법은 훈련 세트에서 랜덤하게 하나의 샘플을 선택해 가파른 경사를 조금 내려간다. 그 다음 훈련 세트에서 랜덤하게 또 다른 샘플을 하나 선택해 경사를 조금 내려간다. 이런 식으로 전체 샘플을 모두 사용할 때까지 계속한다.\n",
        "\n",
        "모든 샘플을 다 사용했는데도 산을 다 내려오지 못했다면 다시 처음부터 시작한다. 훈련 세트에 모든 샘플을 다시 채워 넣고 다시 랜덤하게 하나의 샘플을 선택해 이어서 경사를 내려간다. 확률적 경사 하강법에서 훈련 세트를 한 번 모두 사용하는 과정을 **'에포크(epoch)'**라고 부른다. 일반적으로 경사 하강법은 수십, 수백 번 이상 에포크를 수행한다.\n",
        "\n",
        "확률적 경사 하강법은 1개씩 무작위로 선택해 경사를 내려간다. 이때 여러 개의 샘플을 사용해 경사 하강법을 수행할 수도 있는데 이를 **'미니배치 경사 하강법(minibatch gradient descent)'**라고 한다. 극단적으로 한 번 경사로를 따라 이동하기 위해 전체 샘플을 사용할 수도 있는데 이는 **'배치 경사 하강법(batch gradient descent)'**라고 부른다. 전체 데이터를 사용하기 때문에 가장 안정적인 방법일 수 있지만 전체 데이터를 사용하면 그만큼 컴퓨터 자원을 많이 사용하게 된다. 어떤 경우는 데이터가 너무 많아 한 번에 전체 데이터를 모두 읽을 수 없을지도 모른다.\n",
        "\n",
        "정리하자면, 확률적 경사 하강법은 **훈련 세트를 사용해 산 아래에 있는 최적의 장소로 조금씩 이동하는 알고리즘**이다. 이 때문에 훈련 데이터가 모두 준비되어 있지 않고 매일매일 업데이트되어도 학습을 계속 이어갈 수 있다. 즉, 다시 산꼭대기에서 시작할 필요가 없다.\n",
        "\n",
        "근데 이때 산이라고 하는 것은 무엇일까? 바로 **'손실 함수(loss function)'**이다."
      ],
      "metadata": {
        "id": "4mRfxWBopI2N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**'손실 함수(loss function)'**는 어떤 문제에서 머신러닝 알고리즘이 얼마나 엉터리인지를 측정하는 기준이다. 손실 함수의 값은 작을수록 좋지만 어떤 값이 최솟값인지는 알지 못한다. 가능한 많이 찾아보고 만족할 수준이면 산을 다 내려왔다고 인정해야 한다.\n",
        "\n",
        "우리가 다루는 많은 문제에 필요한 손실 함수는 이미 정의되어 있다. 그럼 생선을 분류하기 위해 어떤 손실 함수를 사용하는지 알아보자.\n",
        "\n",
        "분류에서 손실은 확실하다. 정담을 못 맞히는 것이다. 도미와 빙어를 구분하는 이진 분류 문제를 예로 들어 보자. 도미는 양성 클래스(1), 빙어는 음성 클래스(0)라고 가정해 보자.\n",
        "\n",
        "(예측) (정답)\n",
        "\n",
        "1 ＝ 1\n",
        "\n",
        "0 ≠ 1\n",
        "\n",
        "0 ＝ 0\n",
        "\n",
        "1 ≠ 0\n",
        "\n",
        "위와 같은 예측과 정답이 있다고 가정하자.\n",
        "정확도는 얼마일까? 2/4 이므로 0.5이다. 정확도를 손실함수로 사용할 수 있을까?\n",
        "정확도에 음수를 취하면 -1.0이 가장 낮고 -0.0이 가장 높으므로 괜찮을 수 있다. 하지만 그림과 같이 4개의 샘플만 있다면 가능한 정확도는 0, 0.25, 0.5, 0.75, 1 다섯가지 뿐이다. **정확도가 듬성듬성하다면 경사 하강법을 이용해 조금씩 움직일 수 없다.** 산의 경사면은 연속적이어야 한다.\n",
        "\n",
        "* 손실 함수는 미분 가능해야 한다.\n",
        "\n",
        "이전 '로지스틱 회귀'에서 로지스틱 회귀 모델은 출력한 확률은 **0 ~ 1 어떤 값도 될 수 있었다. 즉, 연속적이다.** 위 샘플 4개의 예측 확률을 각각 0.9, 0.3, 0.2, 0.8이라 가정하자."
      ],
      "metadata": {
        "id": "0k-haQvRsxpG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "첫 번째 샘플의 예측은 0.9 이므로 **양성 클래스의 타깃인 1과 곱한 다음 음수로 바꿀 수 있다.** 이 경우 예측이 1에 가까울수록 좋은 모델이다. 예측이 1에 가까울수록 예측과 타깃의 곱의 음수는 점점 작아진다. 따라서 이 값을 손실 함수로 사용해도 괜찮다.\r\n",
        "\r\n",
        "* 0.9 × 1 -> -0.9 (낮은 손실) [0.9가 예측 확률이다.]\r\n",
        "\r\n",
        "두 번째 샘플의 예측은 아래와 같다.\r\n",
        "\r\n",
        "* 0.3 × 1 -> -0.3 (높은 손실) [0.3이 예측 확률이다.]\r\n",
        "\r\n",
        "세 번째 샘플을 보자. 이 샘플의 타깃은 음성 클래스(0)이다. 이 값을 예측 확률 0.2와 곱하면 무조건 0이 되므로 곤란하다. 이때 **타깃을 양성 클래스처럼 바꾸어 1로 만들고, 예측값도 양성 클래스에 대한 예측으로 바꾸면** 지금까지 했던 방식으로 값을 구할 수 있다.\r\n",
        "\r\n",
        "* (1 - 0.2) * 1 -> -0.8 (낮은 손실) [0.8이 예측 확률이다.]\r\n",
        "\r\n",
        "네 번째 샘플은 아래와 같다.\r\n",
        "\r\n",
        "* (1 - 0.8) * 1 -> -0.2 (높은 손실) [0.2가 예측 확률이다.]\r\n",
        "\r\n",
        "예측 확률을 이런 방식으로 계산하면 **연속적인 손실 함수**를 얻을 수 있다. 예측 확률에 **로그 함수를 적용**하면 더 좋다. 예측 확률의 범위는 0 ~ 1사이인데 로그 함수는 이 사이에서 음수가 되므로 최종 손실 값은 양수가 된다. 손실이 양수가 되면 이해하기 쉬워진다. 또 로그 함수는 0에 가까울수록 아주 큰 음수가 되므로 손실을 아주 크게 만들어 모델에 큰 영향을 미칠 수 있다.\r\n",
        "\r\n",
        "* 타깃이 1일때: -log(예측 확률)\r\n",
        "* 타깃이 0일때: -log(1 - 예측 확률)\r\n",
        "\r\n",
        "이 손실 함수를 **'로지스틱 손실 함수(logistic loss function)'**또는 **'이진 크로스엔트로피 손실 함수(binary cross-entropy loss function)'**이라고 부른다.\r\n",
        "\r\n",
        "* **이 손실 함수를 이용하면 로지스틱 회귀 모델이 만들어진다.**\r\n",
        "\r\n",
        "이진 분류에서는 로지스틱 손실 함수를 이용했지만 다중 분류에서는 **'크로스엔트로피 손실 함수(cross-entropy loss function)'**를 사용한다.\r\n",
        "\r\n",
        "회귀에서는 손실 함수로 평균 절댓값 오차를 사용할 수 있고, **'평균 제곱 오차(mean squared error)'**를 많이 사용한다. 타깃에서 예측을 뺀 값을 제곱한 다음 모든 샘플에 평균한 값이다."
      ],
      "metadata": {
        "id": "bFFwu_O2vlZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "fish_scv_data 파일에서 판다스 데이터프레임을 만들어보자."
      ],
      "metadata": {
        "id": "mnoVpLqey6RO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "import pandas as pd\r\n",
        "fish = pd.read_csv('https://bit.ly/fish_csv_data')\r\n",
        "fish.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Species  Weight  Length  Diagonal   Height   Width\n",
              "0   Bream   242.0    25.4      30.0  11.5200  4.0200\n",
              "1   Bream   290.0    26.3      31.2  12.4800  4.3056\n",
              "2   Bream   340.0    26.5      31.1  12.3778  4.6961\n",
              "3   Bream   363.0    29.0      33.5  12.7300  4.4555\n",
              "4   Bream   430.0    29.0      34.0  12.4440  5.1340"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Species</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Length</th>\n",
              "      <th>Diagonal</th>\n",
              "      <th>Height</th>\n",
              "      <th>Width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bream</td>\n",
              "      <td>242.0</td>\n",
              "      <td>25.4</td>\n",
              "      <td>30.0</td>\n",
              "      <td>11.5200</td>\n",
              "      <td>4.0200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bream</td>\n",
              "      <td>290.0</td>\n",
              "      <td>26.3</td>\n",
              "      <td>31.2</td>\n",
              "      <td>12.4800</td>\n",
              "      <td>4.3056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bream</td>\n",
              "      <td>340.0</td>\n",
              "      <td>26.5</td>\n",
              "      <td>31.1</td>\n",
              "      <td>12.3778</td>\n",
              "      <td>4.6961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bream</td>\n",
              "      <td>363.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>33.5</td>\n",
              "      <td>12.7300</td>\n",
              "      <td>4.4555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bream</td>\n",
              "      <td>430.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>12.4440</td>\n",
              "      <td>5.1340</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "metadata": {
        "id": "YfcS_e9eMZX_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "15f84964-144b-43f5-bf23-0ff2339c84e6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "입력 데이터와 타깃 데이터로 나눈다."
      ],
      "metadata": {
        "id": "CRrd3NViy_Lw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "fish_input = fish[['Weight', 'Length', 'Diagonal', 'Height', 'Width']].to_numpy()\n",
        "fish_target = fish['Species'].to_numpy()"
      ],
      "outputs": [],
      "metadata": {
        "id": "JOVPEMllRcir"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련 세트와 테스트 세트로 나눈다."
      ],
      "metadata": {
        "id": "o_zv-RUlzCtR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_input, test_input, train_target, test_target = train_test_split(fish_input, fish_target, random_state = 42)"
      ],
      "outputs": [],
      "metadata": {
        "id": "BuONhIDCRyeb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련 세트와 테스트 세트의 특성을 표준화 전처리한다. \n",
        "이때 **테스트 세트는 훈련 세트에서 학습한 통계 값으로 변환**해야한다."
      ],
      "metadata": {
        "id": "cZkm66W_zFCO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "ss = StandardScaler()\n",
        "ss.fit(train_input)\n",
        "train_scaled = ss.transform(train_input)\n",
        "test_scaled = ss.transform(test_input)"
      ],
      "outputs": [],
      "metadata": {
        "id": "jc_7mmHYSEzi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "사이킷런에서 확률적 경사 하강법을 제공하는 대표적인 분류용 클래스는 **SGDClassifier**이다. sklearn.linear_model 패키지 아래있다."
      ],
      "metadata": {
        "id": "9R-agrJ4zOJ2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "from sklearn.linear_model import SGDClassifier"
      ],
      "outputs": [],
      "metadata": {
        "id": "wMGQCCwHSTiS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SGDClassifier의 객체를 만들 때 2개의 매개변수를 지정한다. loss는 손실 함수의 종류를 지정한다. loss = 'log'로 지정하면 로지스틱 손실 함수를 지정할 수 있다. max_iter는 수행할 에포크 획수를 지정한다. 10으로 지정하여 전체 훈련 세트를 10회 반복하고 훈련 세트와 테스트 세트의 정확도 점수를 출력해보자."
      ],
      "metadata": {
        "id": "HreoHzytziT2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "sc = SGDClassifier(loss = 'log', max_iter = 10, random_state = 42)\n",
        "sc.fit(train_scaled, train_target)\n",
        "print(sc.score(train_scaled, train_target))\n",
        "print(sc.score(test_scaled, test_target))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.773109243697479\n",
            "0.775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUN3a3UBSkdr",
        "outputId": "6c6180e7-f156-44e2-e22f-ef39b31b813b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 사이킷런은 모델이 충분히 수렴하지 않았다면 ConvergenceWarning 경고를 보낸다. 이러너 경고를 보면 max_iter 매개변수의 값을 늘려 주는 것이 좋다."
      ],
      "metadata": {
        "id": "US-rdSasz652"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "확률적 경사 하강법은 점진적 학습이 가능하다. SGDClassifier 객체를 다시 만들지 않고 훈련한 모델 sc를 추가로 훈련해 보자. 모델을 이어서 훈련할 때는 **partial_fit() 메서드를 사용한다.** fit() 메서드와 사용법이 같지만 호출할 때마다 1 에포크씩 이어서 훈련할 수 있다. partial_fit() 메서드를 호출하고 다시 훈련 세트와 테스트 세트의 점수를 확인해 보자."
      ],
      "metadata": {
        "id": "miwopG6H1AQG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "sc.partial_fit(train_scaled, train_target)\n",
        "print(sc.score(train_scaled, train_target))\n",
        "print(sc.score(test_scaled, test_target))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8151260504201681\n",
            "0.825\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADF8YbNaTQmy",
        "outputId": "6c549964-b03c-464f-faa9-869e0d6bb5e1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "에포크를 한 번 더 실행하니 정확도가 향상되었다. 그럼 얼마나 더 훈련해야 할까? 이 기준에 대해 알아보자.\n",
        "\n",
        "* train_scaled와 train_target을 한꺼번에 모두 사용했지만 SGDClassifier 객체에 한 번에 훈련 세트 전체를 전달해도 이 알고리즘은 **전달한 훈련 세트에서 1개씩 샘플을 꺼내 경사 하강법 단계를 수행**한다."
      ],
      "metadata": {
        "id": "XRRMGpf70JE7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "확률적 경사 하강법은 에포크 횟수에 따라 과소적합이나 과대적합이 될 수 있다. 에포크 횟수가 적으면 모델이 훈련 세트를 덜 학습하고 에포크 횟수가 많으면 훈련 세트를 완전히 학습한다. 즉, **에포크 횟수가 적을 때는 과소적합된 모델일 가능성이 높고, 많을 때는 과대적합된 모델일 가능성이 높다.**\n",
        "\n",
        "훈련 세트 점수는 에포크가 진행될수록 꾸준히 증가하지만 테스트 세트 점수는 어느 순간 감소하기 시작한다. 바로 이 지점이 모델이 과대적합되기 시작하는 곳이다. 과대적합이 시작하기 전에 훈련을 멈추는 것을 **'조기 종료(early stopping)'**라고 한다.\n",
        "\n",
        "그럼 그래프를 그려보도록 하자."
      ],
      "metadata": {
        "id": "Z-evCVSZ1iF2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "import numpy as np\n",
        "sc = SGDClassifier(loss = 'log', random_state = 42)\n",
        "train_score = []\n",
        "test_score = []\n",
        "classes = np.unique(train_target)\n",
        "\n",
        "for _ in range(300):\n",
        "  sc.partial_fit(train_scaled, train_target, classes = classes)\n",
        "  train_score.append(sc.score(train_scaled, train_target))\n",
        "  test_score.append(sc.score(test_scaled, test_target))"
      ],
      "outputs": [],
      "metadata": {
        "id": "ftJPONA6Tm7y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* partial_fit() 메서드만 사용하려면 훈련 세트에 있는 전체 클래스의 레이블을 partial_fit() 메서드에 전달해야 한다. 이를 위해 np.unique() 함수로 train_target에 있는 7개 생선의 목록을 만든다."
      ],
      "metadata": {
        "id": "p7_4q511098G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_score)\n",
        "plt.plot(test_score)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "BM93jVM9Uyas",
        "outputId": "c4991fc7-f18e-4a5d-c49d-d378d0a24609"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터가 작아 잘 드러나지 않지만, 백 번째 에포크 이후에 훈련 세트와 테스트 세트의 점수가 조금씩 벌어지고 있다. 즉, 백 번째 에포크가 적절한 반복 횟수이다.\n",
        "\n",
        "그럼 SGDClassifier의 반복 횟수를 100에 맞추고 모델을 다시 훈련해 보자."
      ],
      "metadata": {
        "id": "_g3WjZro2vrX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "sc = SGDClassifier(loss = 'log', max_iter = 100, tol = None, random_state = 42)\n",
        "sc.fit(train_scaled, train_target)\n",
        "print(sc.score(train_scaled, train_target))\n",
        "print(sc.score(test_scaled, test_target))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.957983193277311\n",
            "0.925\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wucNBM8gVEZS",
        "outputId": "9ec05823-b1f1-4b85-87c1-eb3d796e2321"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SGDClassifier는 일정 에포크 동안 성능이 향상되지 않으면 더 훈련하지 않고 자동으로 멈춘다. tol 매개변수에서 향상될 최솟값을 지정한다. 우리는 자동으로 멈추지 않기위해 tol 매개변수를 None으로 지정하고 max_iter은 100으로 지정했다.\n",
        "\n",
        "* SGDRegressor는 확률적 경사 하강법을 사용한 회귀 알고리즘을 제공한다. 사용법은 SGDClassifier와 동일하다."
      ],
      "metadata": {
        "id": "-80iPqzY2-RO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "참고로 loss에 대해 조금 알아보자.\n",
        "\n",
        "loss 매개변수의 기본값은 **'hinge'**이다. **'힌지 손실(hinge loss)'**은 **'서포트 백터 머신(support vector machine)'**이라 불리는 또 다른 머신러닝 알고리즘을 위한 손실 함수이다. 일단 서포트 백터 머신이 널리 사용하는 머신러닝 알고리즘 중 하나라는 점과 SGDClassifier가 여러 종류의 손술 함수를 loss 매개변수에 지정하여 다양한 머신러닝 알고리즘을 지원하다는 것만 알아두자.\n",
        "\n",
        "힌지 손실을 사용해 모델을 훈련해보자."
      ],
      "metadata": {
        "id": "0TjAKZYT3X1v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "sc = SGDClassifier(loss = 'hinge', max_iter = 100, tol = None, random_state = 42)\n",
        "sc.fit(train_scaled, train_target)\n",
        "print(sc.score(train_scaled, train_target))\n",
        "print(sc.score(test_scaled, test_target))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9495798319327731\n",
            "0.925\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqY8cLtWVgWq",
        "outputId": "8138e4f5-9923-4a8c-8385-7c3191661673"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 정리\n",
        "\n",
        "핵심 포인트\n",
        "* 확률적 경사 하강법: **훈련 세트에서 샘플 하나씩 꺼내 손실 함수의 경사를 따라 최적의 모델을 찾는 알고리즘**이다. 샘플을 하나씩 사용하지 않고 여러 개를 사용하면 **미니배치 경사 하강법**, 한 번에 전체 샘플을 사용하면 **배치 경사 하강법**이 된다.\n",
        "* 손실 함수: **확률적 경사 하강법이 최적화할 대상**이다. 이진 분류에서는 로지스틱 회귀(또는 이진 크로스엔트로피) 손실 함수를 사용한다. 다중 분류에서는 크로스엔트로프 손실 함수를 사용하고 회귀 문제에서는 평균 제곱 오차 손실 함수를 사용한다.\n",
        "* 에포크: **확률적 경사 하강법에서 전체 샘플을 모두 사용하는 한 번 반복을 의미한다.** 일반적으로 경사 하강법 알고리즘은 수십에서 수백 번의 에포크를 반복한다.\n",
        "\n",
        "핵심 패키지와 함수\n",
        "\n",
        "scikit-learn\n",
        "* SGDClassifier: **확률적 경사 하강법을 사용한 분류 모델을 만든다.** **loss 매개변수**는 최적화할 손실 함수를 지정하며 기본값은 'hinge' 손실 함수이다. 로지스틱 회귀를 위해서는 'log'로 지정한다. **penalty 매개변수**에서 규제의 종류를 지정한다. 기본값은 L2 규제를 위한 'l2'이고 L1 규제는 'l1'으로 지정한다. 규제 강도는 **alpha 매개변수**에서 지정한다. 기본값은 0.0001이다. **max_iter 매개변수**는 에포크 횟수를 지정하며 기본값은 1,000이다. **tol 매개변수**는 반복을 멈출 조건이며 **n_iter_no_change 매개변수**에서 지정한 에포크 동안 손실이 tol 만큼 줄어들지 않으면 알고리즘이 중단된다. tol 매개변수의 기본값은 0.001이고 n_iter_no_change 매개변수의 기본값은 5이다."
      ],
      "metadata": {
        "id": "DzwWz3iF33RP"
      }
    }
  ]
}