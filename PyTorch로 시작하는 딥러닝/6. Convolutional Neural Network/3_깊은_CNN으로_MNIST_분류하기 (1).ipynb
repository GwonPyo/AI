{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3. 깊은 CNN으로 MNIST 분류하기.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "이전보다 더 깊은 CNN 모델을 구현한 코드이다."
      ],
      "metadata": {
        "id": "dUVuOTTvRx3j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwjZmgPvOtWZ",
        "outputId": "ea509c3d-e61b-4025-c16f-53fcd6ac327d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch:    1] cost = 0.19128488\n",
            "[Epoch:    2] cost = 0.0534425043\n",
            "[Epoch:    3] cost = 0.0365854688\n",
            "[Epoch:    4] cost = 0.0292578582\n",
            "[Epoch:    5] cost = 0.0236950871\n",
            "[Epoch:    6] cost = 0.0206277445\n",
            "[Epoch:    7] cost = 0.0178213771\n",
            "[Epoch:    8] cost = 0.0135748684\n",
            "[Epoch:    9] cost = 0.0119404383\n",
            "[Epoch:   10] cost = 0.0113130035\n",
            "[Epoch:   11] cost = 0.0103591066\n",
            "[Epoch:   12] cost = 0.0105378544\n",
            "[Epoch:   13] cost = 0.00701278634\n",
            "[Epoch:   14] cost = 0.00926021487\n",
            "[Epoch:   15] cost = 0.00699869404\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# set device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda': torch.cuda.manual_seed_all(777)\n",
        "\n",
        "# set parmeters\n",
        "learning_rate = 0.001\n",
        "training_epochs = 15\n",
        "batch_size = 100\n",
        "\n",
        "# define datasets\n",
        "mnist_train = dsets.MNIST(root='MNIST_Data/',\n",
        "                         train=True,\n",
        "                         transform=transforms.ToTensor(),\n",
        "                         download=True)\n",
        "mnist_test = dsets.MNIST(root='MNIST_Data/',\n",
        "                        train=False,\n",
        "                        transform=transforms.ToTensor(),\n",
        "                        download=True)\n",
        "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size=len(mnist_test), shuffle=False)\n",
        "\n",
        "# design model\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.keep_prob = 0.5\n",
        "    # First Layer (Convolution Layer)\n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    # Second Layer (Convolution Layer)\n",
        "    self.layer2 = nn.Sequential(\n",
        "        nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    # Third Layer (Convolution Layer)\n",
        "    self.layer3 = nn.Sequential(\n",
        "        nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
        "    )\n",
        "    # Forth Layer (Fully Connected Layer)\n",
        "    self.fc1 = nn.Linear(4*4*128, 625, bias=True)\n",
        "    nn.init.xavier_uniform_(self.fc1.weight)\n",
        "    self.layer4 = nn.Sequential(\n",
        "        self.fc1,\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=1-self.keep_prob)\n",
        "    )\n",
        "\n",
        "    # Fifth Layer (Fully Connected Layer)\n",
        "    self.layer5 = nn.Linear(625, 10, bias=True)\n",
        "    nn.init.xavier_uniform_(self.layer5.weight)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    out = self.layer1(x)\n",
        "    out = self.layer2(out)\n",
        "    out = self.layer3(out)\n",
        "    out = out.view(out.size(0), -1)\n",
        "    out = self.layer4(out)\n",
        "    out = self.layer5(out)\n",
        "    return out\n",
        "\n",
        "model = CNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "model.train()\n",
        "total_batch = len(train_loader)\n",
        "for epoch in range(training_epochs):\n",
        "  avg_cost = 0\n",
        "  for x, y in train_loader:\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    hypothesis = model(x)\n",
        "    cost = criterion(hypothesis, y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    avg_cost += cost / total_batch\n",
        "  \n",
        "  print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  for x, y in test_loader:\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    \n",
        "    prediction = model(x)\n",
        "    correct_prediction = torch.argmax(prediction, 1) == y\n",
        "    accuracy = correct_prediction.float().mean()\n",
        "    print('Accuracy:', accuracy.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tixTeuelV9Dg",
        "outputId": "71beedd9-6d80-4802-818d-3c9a9676df4e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.991599977016449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "출처: https://wikidocs.net/63618"
      ],
      "metadata": {
        "id": "YaNBncwXcoyq"
      }
    }
  ]
}