{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1. Linear Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "TQoHz2MhzM7T",
        "wlT6TsND3tZk",
        "mjDx-LAo64M-",
        "9JpGidM5lXpw"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## <strong> 1. 데이터에 대한 이해 </strong>"
      ],
      "metadata": {
        "id": "TQoHz2MhzM7T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3> <strong> 1.1 훈련/테스트 데이터셋 </strong> </h3>\n",
        "\n",
        "예측을 위해 학습에 사용하는 데이터를 **훈련 데이터셋(training dataset)**이라고 한다. <br>\n",
        "학습 이후 모델이 얼마나 잘 작동하는지 판별하는 데이터셋을 **테스트 데이터셋(test dataset)**이라고 한다.\n"
      ],
      "metadata": {
        "id": "wBnqbMrc0HLz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3> <strong> 1.2 훈련 데이터셋의 구성 </strong> </h3>\n",
        "\n",
        "모델을 학습시키기 위한 데이터는 파이토치의 텐서의 형태를 가지고 있어야 한다."
      ],
      "metadata": {
        "id": "avJRtT-e1oex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[1], [2], [3]])"
      ],
      "metadata": {
        "id": "PRS77bI93gfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <strong> 2. 가설 수립 </strong> "
      ],
      "metadata": {
        "id": "wlT6TsND3tZk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "머신 러닝에서 식을 세울때 이 식을 **가설(Hypothesis)**이라고 한다. <br> 머신 러닝에서 가설은 임의로 추측해서 세워보는 식일 수도 있고 알고 있는 식일 수도 있다. <br>\n",
        "\n",
        "선형 회귀의 가설은 이미 널리 알려져 있다. <br>\n",
        "선형 회귀란 학습 데이터와 가장 잘 맞는 하나의 직선을 찾는 일이다. <br>\n",
        "이때 선형 회귀의 가설은 아래와 같다.\n",
        "\n",
        "$y=Wx+b$\n",
        "\n",
        "이때 W를 **가중치(Weight)**, b를 **편향(bias)**라고 한다."
      ],
      "metadata": {
        "id": "cqRgLb0c4PYd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <strong> 3. 비용 함수에 대한 이해 </strong> "
      ],
      "metadata": {
        "id": "mjDx-LAo64M-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "다음 용어들은 모두 같은 용어로 생각하면 된다.\n",
        "\n",
        "* **cost function / loss function / error function / objective function**\n",
        "\n",
        "손실 함수란 예측값과 실제 정답간의 오차라고 생각할 수 있다. <br> \n",
        "즉, **손실 함수의 값을 작게 하는 것이 우리의 목표**로 선형 회귀의 경우 손실 함수의 값을 최소로 하는 W와 b를 탐색하게 된다. <br>\n",
        "손실 함수의 예로는 평균 제곱 오차(Mean Squared Error, MSE) 등이 있다. <br>\n",
        "\n"
      ],
      "metadata": {
        "id": "R7owerT16--d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <strong> 4. 옵티마이저 - 경사 하강법 </strong> "
      ],
      "metadata": {
        "id": "9JpGidM5lXpw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "우리는 비용 함수의 값을 최소로 하는 W와 b를 찾아야 한다. <br>\n",
        "이때 W와 b를 찾는 데 사용되는 것이 옵티마이저(Optimizer)로 최적화 알고리즘이라고도 불린다. <br>\n",
        "이 옵티마이저 알고리즘을 통해 적절한 W와 b를 찾아내는 과정을 **학습(training)**이라고 부른다. <br>\n",
        "이때 경사 하강법(gradient descent)는 옵티마이저의 가장 기본적인 알고리즘이다."
      ],
      "metadata": {
        "id": "ul0Ch-61lbM0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "좌표상에 임의의 4개의 점을 입력받고 해당 값들을 예측하기 위한 선형(직선) 방정식을 구한다고 하자. <br>\n",
        "단, bias는 0라고 가정하자. <br>\n",
        "이때 기울기가 지나치게 크거나 작으면 오차값이 매우 커질 것이다. <br>\n",
        "즉, cost함수와 W의 관계를 그래프로 표현하면 아래의 그래프가 그려진다.\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "rzFSqXH4nD1h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이때 우리의 목표는 cost가 가장 최소값을 가지게 하는 W를 찾는 것이다. <br>\n",
        "즉, 맨 아래 볼록한 부분의 W값을 찾아야 한다. <br>\n",
        "이를 위해 기계는 임의의 초기값 W를 지정하고, 맨 아래의 볼록한 부분을 향해 점차 W의 값을 수정해간다. <br>\n",
        "이 과정을 수행해주는 것이 **경사 하강법(gradient descent)**이다. <br>"
      ],
      "metadata": {
        "id": "5iZ80oTknySB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "위 그림의 초록색 선은 W가 임의의 값을 가질 때 그래프 상의 접선의 기울기를 그려준 것이다. <br>\n",
        "이때 맨 아래의 볼록한 부분으로 갈수록 접선의 기울기는 점차 작아지고 맨 아래의 볼록한 부분의 점선의 기울기는 0이 된다.\n",
        "\n",
        "즉, cost가 0이 되는 지점은 미분값이 0이 되는 지점이다. <br>\n",
        "경사 하강법은 비용 함수를 미분하여 W에 대한 접선의 기울기를 구하고, 기울기가 낮은 방향으로 W의 값을 변경하는 작업을 반복하게 된다. <br>\n",
        "이때 기울기는 다음과 같이 표현된다.\n",
        "\n",
        "$기울기 = \\frac{\\partial cost(W)}{\\partial W}$ "
      ],
      "metadata": {
        "id": "kTKwZ6Hroabw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "임의의 변수에 대한 미분값의 부호에 동일한 방향으로 해당 변수를 이동하면 함수값은 증가한다. <br>\n",
        "따라서 경사 하강법의 경우 기울기가 음수인 경우 양의 방향으로, 양수인 경우 음의 방향으로 이동시켜야 한다. <br>\n",
        "따라서 다음과 같은 식을 작성할 수 있다.\n",
        "\n",
        "$W = W-α\\frac{∂}{∂W}cost(W)$\n",
        "\n",
        "이때 $α$를 **학습률(learning rate)**라고 하며 W의 값을 변경할 때 얼마나 크게 변경할지를 결정한다. \n",
        "<br>\n",
        "실제 선형 회귀에서는 W와 b를 동시에 경사 하강법을 수행하면서 최적의 W와 b값을 찾아낸다."
      ],
      "metadata": {
        "id": "AXRzxQlvpy-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <strong> 5. 파이토치로 선형 회귀 구현하기 </strong> "
      ],
      "metadata": {
        "id": "ELI7nNc0r1Xe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3> <strong> 5.1 기본 셋팅 </strong> </h3>\n",
        "\n",
        "아래는 기본 셋팅이며 이후에도 같은 결과가 나오도록 random seed를 지정해주었다."
      ],
      "metadata": {
        "id": "K7HXeUWgr4mc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "GSoCYuhwr_CK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFykcsmPsHmc",
        "outputId": "fb111a32-8a23-4130-e8dd-e3810564efd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f6ebd76af70>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3> <strong> 5.2 변수 선언 </strong> </h3>\n",
        "\n",
        "훈련 데이터 x_train, y_train을 선언하자."
      ],
      "metadata": {
        "id": "9J6wrrctsJS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[2], [4], [6]])"
      ],
      "metadata": {
        "id": "gsoJId0OsYsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3> <strong> 5.3 가중치/편향 초기화 </strong> </h3>\n",
        "\n",
        "선형 회귀란 학습 데이터와 잘 맞는 하나의 직선을 찾는 일이다. <br>\n",
        "이때 가장 잘 맞는 직선을 정의하는 것이 W와 b이고 우리는 해당 값을 학습해야한다. <br>\n",
        "\n",
        "먼저 가중치 W를 0으로 초기화하자."
      ],
      "metadata": {
        "id": "HtkHG8ebsmZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W = torch.zeros(1, requires_grad=True) # 0으로 초기화, 학습을 통해 변경되는 값임을 명시\n",
        "print(W)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIORBlKftBLT",
        "outputId": "234efb3a-e9f4-407a-e70e-54a8a7ae9da0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**requires_grad=True**를 인자로 넘기면 해당 변수는 학습을 통해 값이 변경되는 변수임을 의미한다. \n",
        "\n",
        "b도 동일하게 선언해보자."
      ],
      "metadata": {
        "id": "iA05_5-6tMIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b = torch.zeros(1, requires_grad=True)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AY-vWT3mtXms",
        "outputId": "5227912d-069f-4834-c00a-e069737bb044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3> <strong> 5.4 가설 세우기 </strong> </h3>\n",
        "\n",
        "파이토치 코드 상으로 직선의 방정식에 해당하는 가설을 선언한다.\n"
      ],
      "metadata": {
        "id": "7HfYFJsEtcet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hypothesis = x_train*W + b\n",
        "print(hypothesis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnuKBWpzvoIe",
        "outputId": "f4095fc0-a6de-448f-bf8d-ddd2bf810276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [0.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3> <strong> 5.5 비용 함수 선언하기 </strong> </h3>\n",
        "\n",
        "산형 회귀의 비용 함수인 평균 제곱 오차를 선언하자."
      ],
      "metadata": {
        "id": "dBq9l72JvwCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cost = torch.mean((hypothesis-y_train)**2)\n",
        "print(cost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrmdy6sDv7BB",
        "outputId": "cd1985ee-84fe-4284-b31a-004a002596b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(18.6667, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3> <strong> 5.6 경사 하강법 구현하기 </strong> </h3>\n",
        "\n",
        "아래의 **SGD**는 경사 하강법의 일종이며 lr은 학습률을 의미한다. <br>\n",
        "학습 대상인 W와 b가 입력된다."
      ],
      "metadata": {
        "id": "2pkGv4cjwFP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD([W, b], lr=0.01)"
      ],
      "metadata": {
        "id": "zRBJH4BUwiTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**optimizer.zero_grad()**를 실행해서 미분을 통해 얻은 기울기를 0으로 초기화 해야한다. <br>\n",
        "기울기를 초기화해야 새로운 가중치 편향에 대해서 새로운 기울기를 구할 수 있다. <br>\n",
        "그리고 **cost.backward() 함수**를 호출하면 가중치 W와 편향 b에 대한 기울기가 계산된다. <br>\n",
        "마지막으로 최적화 함수 optimizer의 **step()**을 호출하면 인수로 들어갔던 W와 b에서 리턴되는 변수들의 기울기에 학습률을 곱해 <br> 빼주면서 업데이트해준다."
      ],
      "metadata": {
        "id": "XxbZCkLdwoUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer.zero_grad() # gradient를 0으로 초기화\n",
        "cost.backward()       # 비용 함수를 미분하여 gradient 계산\n",
        "optimizer.step()      # W와 b를 업데이트"
      ],
      "metadata": {
        "id": "tJ9XElTyxiDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3> <strong> 5.7 전체 코드 </strong> </h3>"
      ],
      "metadata": {
        "id": "fW94gxg1yDiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 선언\n",
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[2], [4], [6]])\n",
        "\n",
        "# 모델 초기화\n",
        "W = torch.zeros(1, requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "# 옵티마이저 설정\n",
        "optimizer = optim.SGD([W, b], lr=0.01)\n",
        "\n",
        "# 에포크 횟수 지정\n",
        "nb_epochs = 1999\n",
        "for epoch in range(nb_epochs):\n",
        "  # H(x) 계산\n",
        "  hypothesis = x_train*W + b\n",
        "\n",
        "  # cost 계산\n",
        "  cost = torch.mean((hypothesis-y_train)**2)\n",
        "\n",
        "  # cost로 H(x) 개선\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, W.item(), b.item(), cost.item()\n",
        "        ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlpXyI6tyLsh",
        "outputId": "3c848b1b-daf7-4e0f-bf01-29f9f5f13fb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1999 W: 0.187, b: 0.080 Cost: 18.666666\n",
            "Epoch  100/1999 W: 1.746, b: 0.578 Cost: 0.048171\n",
            "Epoch  200/1999 W: 1.800, b: 0.454 Cost: 0.029767\n",
            "Epoch  300/1999 W: 1.843, b: 0.357 Cost: 0.018394\n",
            "Epoch  400/1999 W: 1.876, b: 0.281 Cost: 0.011366\n",
            "Epoch  500/1999 W: 1.903, b: 0.221 Cost: 0.007024\n",
            "Epoch  600/1999 W: 1.924, b: 0.174 Cost: 0.004340\n",
            "Epoch  700/1999 W: 1.940, b: 0.136 Cost: 0.002682\n",
            "Epoch  800/1999 W: 1.953, b: 0.107 Cost: 0.001657\n",
            "Epoch  900/1999 W: 1.963, b: 0.084 Cost: 0.001024\n",
            "Epoch 1000/1999 W: 1.971, b: 0.066 Cost: 0.000633\n",
            "Epoch 1100/1999 W: 1.977, b: 0.052 Cost: 0.000391\n",
            "Epoch 1200/1999 W: 1.982, b: 0.041 Cost: 0.000242\n",
            "Epoch 1300/1999 W: 1.986, b: 0.032 Cost: 0.000149\n",
            "Epoch 1400/1999 W: 1.989, b: 0.025 Cost: 0.000092\n",
            "Epoch 1500/1999 W: 1.991, b: 0.020 Cost: 0.000057\n",
            "Epoch 1600/1999 W: 1.993, b: 0.016 Cost: 0.000035\n",
            "Epoch 1700/1999 W: 1.995, b: 0.012 Cost: 0.000022\n",
            "Epoch 1800/1999 W: 1.996, b: 0.010 Cost: 0.000013\n",
            "Epoch 1900/1999 W: 1.997, b: 0.008 Cost: 0.000008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "결과적으로 훈련 과정에서 W와 b는 훈련 데이터에 맞는 직선을 표현하기 위한 적절한 값으로 변화한다. <br>\n",
        "이때 **에포크(epoch)**란 전체 훈련 데이터가 학습에 한 법 사용된 주기를 말한다."
      ],
      "metadata": {
        "id": "kVaAsA5azP8w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <strong> 6. optimizer.zero_grad()가 필요한 이유 </strong> "
      ],
      "metadata": {
        "id": "0LkfyCSTzpaj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "파이토치는 **미분을 통해 얻은 기울기를 이전에 계산된 기울기 값에 누적시키는 특징이 있다.**"
      ],
      "metadata": {
        "id": "NqrfSROBzw4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "w = torch.tensor(2.0, requires_grad=True)\n",
        "\n",
        "nb_epochs = 5\n",
        "for epoch in range(nb_epochs+1):\n",
        "  z = 2*w\n",
        "\n",
        "  z.backward()\n",
        "  print(\"수식을 w로 미분한 값:\", w.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMMtefDvz4G5",
        "outputId": "260f8342-1edd-4113-9460-c6663ffc88a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "수식을 w로 미분한 값: tensor(2.)\n",
            "수식을 w로 미분한 값: tensor(4.)\n",
            "수식을 w로 미분한 값: tensor(6.)\n",
            "수식을 w로 미분한 값: tensor(8.)\n",
            "수식을 w로 미분한 값: tensor(10.)\n",
            "수식을 w로 미분한 값: tensor(12.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위처럼 미분값 2가 누적되므로 미분값을 계속 0으로 초기화해야 한다."
      ],
      "metadata": {
        "id": "6spJu8iR0ROh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "출처: https://wikidocs.net/53560"
      ],
      "metadata": {
        "id": "TLNvIkoy2JG7"
      }
    }
  ]
}